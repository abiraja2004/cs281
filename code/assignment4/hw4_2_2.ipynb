{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import autograd.numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import multivariate_normal as N\n",
    "from scipy.stats import norm as N1\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "# Each row is formatted as [User ID] [Joke ID] [Rating]\n",
    "ratingsFile =  \"ratings.dat\"\n",
    "allData = pd.read_csv(ratingsFile, sep=\" \", header=None)\n",
    "allData = allData.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allData.columns = ['UserID', 'JokeID', 'Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numTrain = 100000\n",
    "numTest = 100000\n",
    "train = allData[:numTrain]\n",
    "test = allData[numTrain:numTrain + numTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainUserIDs = sorted(train['UserID'].unique())\n",
    "trainJokeIDs = sorted(train['JokeID'].unique())\n",
    "testUserIDs = sorted(test['UserID'].unique())\n",
    "testJokeIDs = sorted(test['JokeID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note that not all users in the testing set are in the training set! \n",
    "sorted(trainJokeIDs) == sorted(testJokeIDs), sorted(trainUserIDs) == sorted(testUserIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We precompute the ratings each user gave to the movies he or she rated\n",
    "def createMappings():\n",
    "    '''\n",
    "    Given a data set, creates the mappings necessary for quick access of results\n",
    "    '''\n",
    "    userIds = trainUserIDs\n",
    "    jokeIds = trainJokeIDs\n",
    "    \n",
    "    # This is a mapping from userID to an numpy array of ratings for that user.\n",
    "    userToRatings = {}\n",
    "    # This is a mapping from userID to a list of indexes corresponding to the jokes rated by the user.\n",
    "    userToJokeIDs = {}\n",
    "    \n",
    "    # Same as above, but in reverse.\n",
    "    jokeToRatings = {}\n",
    "    jokeToUserIDs = {}\n",
    "    \n",
    "    # Fill the mappings per users\n",
    "    for userID in userIds:\n",
    "        userToRatings[userID] = np.array(train[train.UserID == userID].Rating.values)\n",
    "        userToJokeIDs[userID] = np.array(train[train.UserID == userID].JokeID.values)\n",
    "        \n",
    "    for jokeID in jokeIds:\n",
    "        jokeToRatings[jokeID] = np.array(train[train.JokeID == jokeID].Rating.values)\n",
    "        jokeToUserIDs[jokeID] = np.array(train[train.JokeID == jokeID].UserID.values)\n",
    "        \n",
    "    return userToRatings, userToJokeIDs, jokeToRatings, jokeToUserIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainUtoR, trainUToJ, trainJtoR, trainJToU = createMappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We're going to create a mapping from userID to row_index in U\n",
    "# Also, a mapping from jokeID to row_index in V\n",
    "# Additionally, a mapping from userID to row_index in V of jokes rated by the user\n",
    "# and a mapping from jokeID to row_index in U of the users that rated that joke\n",
    "def createInitialParams(K, sigma2u, sigma2v, users, jokes, UtoJ, JtoU):\n",
    "    '''\n",
    "    Returns initial parameters of our U,V distributions along with the mappings described in the table above.\n",
    "    Input parameters K, the number of laten variables, the variance of U,V distributions respectively,\n",
    "    a list of userIds, list of jokeIds, a mapping from userIDs to jokes they've rated, and a mapping from \n",
    "    jokeIDs to users that have rated them, in that order. \n",
    "    '''\n",
    "    # Maps from Users/Jokes to rows\n",
    "    UserToU = { user : i for i, user in enumerate(users)}\n",
    "    JokeToV = { joke : i for i, joke in enumerate(jokes)}\n",
    "    \n",
    "    # Now we create the more complicated mapping from Users to JokeRowsRater and Joke to UserRowsRatedBy\n",
    "    UserToV = { user: np.array([JokeToV[joke] for joke in UtoJ[user]]) for user in users}\n",
    "    JokeToU = { joke: np.array([UserToU[user] for user in JtoU[joke]]) for joke in jokes}\n",
    "    \n",
    "    # Lastly, we create our parameters for the normal distributions from which we sample U,V\n",
    "    mus = { user: np.zeros(K) for user in users}\n",
    "    nus = { joke: np.zeros(K) for joke in jokes}\n",
    "    Sigmas = { user: sigma2u * np.identity(K) for user in users}\n",
    "    Taus = { joke: sigma2v * np.identity(K) for joke in jokes}\n",
    "    \n",
    "    return mus, nus, Sigmas, Taus, UserToU, UserToV, JokeToU, JokeToV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Constant values that won't change. The only parameter that changes is K.\n",
    "sigma2u, sigma2v, sigma2 = 5.0, 5.0, 1.0\n",
    "\n",
    "# Start epoch iterations.\n",
    "# We do gibs sampling on the specified value of K, the number of latent variables to consdier.\n",
    "def gibbsSampling(K, EPOCHS = 100):\n",
    "    # We start by creating our subsets of parameters using the mappings we pre-computed with createMappings function.\n",
    "    # The function returns a list of the likelihood results on the test and training for each epoch.\n",
    "    '''\n",
    "    trainUserIDs = a list of ids in the training set for users\n",
    "    trainJokeIDs = a list of ids in the training set for jokes\n",
    "    trainUtoR - training user to list of ratings\n",
    "    trainUToJ - training user to list of joke ids rated\n",
    "    trainJtoR - training joke to list of raings \n",
    "    trainJToU - training joke to list of usersids that rated it\n",
    "    '''\n",
    "    print \"Initializing prior distributions...\"\n",
    "    mus, nus, Sigmas, Taus, UserToU, UserToV, JokeToU, JokeToV = createInitialParams(\n",
    "        K,sigma2u, sigma2v, trainUserIDs, trainJokeIDs, trainUToJ, trainJToU)\n",
    "    \n",
    "    # Additionally, we create distionaries of inverse Sigmas and Taus\n",
    "    inverseSigmas = {user : np.linalg.inv(Sigmas[user]) for user in Sigmas} \n",
    "    inverseTaus = {joke : np.linalg.inv(Taus[joke]) for joke in Taus}\n",
    "    \n",
    "    print \"Initialized prior distributions...\"\n",
    "    \n",
    "    print \"Initializing random samples of U,V...\"\n",
    "    U0 = np.zeros((len(trainUserIDs), K))\n",
    "    V0 = np.zeros((len(trainJokeIDs), K))\n",
    "    for user in trainUserIDs:\n",
    "        U0[UserToU[user], :] = N(mus[user], Sigmas[user])\n",
    "        \n",
    "    for joke in trainJokeIDs:\n",
    "        V0[JokeToV[joke], :] = N(nus[joke], Taus[joke])\n",
    "        \n",
    "    Us = {}\n",
    "    Vs = {}\n",
    "    Us[0] = U0\n",
    "    Vs[0] = V0\n",
    "    print \"Finished initializing U,V...\"\n",
    "        \n",
    "    print \"Initializing epoch iterations!....\"    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # Iterate over the users\n",
    "        U = np.zeros(Us[epoch].shape)\n",
    "        for user in trainUserIDs:\n",
    "            # Update the mu and Sigma\n",
    "            Vi = Vs[epoch][UserToV[user], :] # The jokes rated by user i\n",
    "            Rij = trainUtoR[user] # The ratings by user i\n",
    "            inverseSigmaNew = inverseSigmas[user] + Vi.T.dot(Vi)\n",
    "            SigmaNew = np.linalg.inv(inverseSigmaNew)\n",
    "            muNew = SigmaNew.dot(Vi.T.dot(Rij) + inverseSigmas[user].dot(mus[user]))\n",
    "            \n",
    "            # Sample a new latent vector for this user.\n",
    "            U[UserToU[user], :] = N(muNew, SigmaNew)\n",
    "            \n",
    "            # Store new values\n",
    "            mus[user] = muNew\n",
    "            Sigmas[user] = SigmaNew\n",
    "            inverseSigmas[user] = inverseSigmaNew\n",
    "            \n",
    "        print \"Finished updating the U matrix...\"\n",
    "        \n",
    "        # Iteratve over the jokes\n",
    "        V = np.zeros(Vs[epoch].shape)\n",
    "        for joke in trainJokeIDs:\n",
    "            # Update the nu and Tau\n",
    "            Ui = Us[epoch][JokeToU[joke], :] # The users rated that rated our joke\n",
    "            Rij = trainJtoR[joke] # The ratings of the joke\n",
    "            inverseTauNew = inverseTaus[joke] + Ui.T.dot(Ui)\n",
    "            TauNew = np.linalg.inv(inverseTauNew)\n",
    "            nuNew = TauNew.dot(Ui.T.dot(Rij) + inverseTaus[joke].dot(nus[joke]))\n",
    "            \n",
    "            # Sample a new laten vector for this user.\n",
    "            V[JokeToV[joke], :] = N(nuNew, TauNew)\n",
    "            \n",
    "            # Store new values\n",
    "            nus[joke] = nuNew\n",
    "            Taus[joke] = TauNew\n",
    "            inverseTaus[joke] = inverseTauNew\n",
    "            \n",
    "        print \"Finished updating the V matrix....\"\n",
    "            \n",
    "        # Store the results!\n",
    "        Us[epoch + 1] = U\n",
    "        Vs[epoch + 1] = V\n",
    "        \n",
    "        print \"Finished updating the results!...\"\n",
    "        print \"Done with Epoch {}\".format(epoch)\n",
    "    \n",
    "    print \"Finished Epochs!\"\n",
    "    \n",
    "    # We return the stack of Us ans well as the mappings from Users to U/V and from Jokes to U/V\n",
    "    return Us, Vs, UserToU, UserToV, JokeToU, JokeToV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createRatingSet(data, nusers, njokes, UserToU, JokeToV, filename='test.out'):\n",
    "    '''\n",
    "    Given a pandas data frame, creates a matrix R with the ratings of each user filled in.\n",
    "    '''\n",
    "    try:\n",
    "        R = np.loadtxt(filename)\n",
    "    except IOError:\n",
    "        R = np.zeros((nusers, njokes))\n",
    "        ignored = 0\n",
    "        for i, row in data.iterrows():\n",
    "            try:\n",
    "                i = UserToU[row.UserID]\n",
    "                j = JokeToV[row.JokeID]\n",
    "                R[i,j] = row.Rating\n",
    "            except KeyError:\n",
    "                # We don't have this user or joke in our training set, so we just ignore it?\n",
    "                ignored += 1\n",
    "                pass\n",
    "            \n",
    "        print \"Ignored a total of {} users/ratings that don't exist in training set\".format(ignored)\n",
    "\n",
    "        np.savetxt(filename, R)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonZeroSubtract(x,y):\n",
    "    '''\n",
    "    Computs x-y iff x \\neq 0, otherwise returns 0.\n",
    "    '''\n",
    "    return x-y if x != 0 else 0\n",
    "\n",
    "vectSub = np.vectorize(nonZeroSubtract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can calculate these after as long as we return our stack of Us.\n",
    "def getTrainTestLikelihood(Us, Vs, UserToU, JokeToV, useEpochs=True):\n",
    "    '''\n",
    "    Given the sequence of created Us and Vs during the Epochs, we calculate the log likelihood on the\n",
    "    training and testing data. We also need the mappings from UserID to index in U and JokeId to index in V.\n",
    "    \n",
    "    If epochs is true, then this returns the averages for \n",
    "    '''\n",
    "    # We calculate the results profressively, so let us iterated over the sorted keys for the epochs.\n",
    "    assert(sorted(Us.keys()) == sorted(Vs.keys()))\n",
    "    epochs = sorted(Us.keys())\n",
    "    print \"Epochs: {}\".format(epochs)\n",
    "    assert(len(epochs) > 0)\n",
    "    # The running mean for U and V\n",
    "    UMean = np.zeros(Us[epochs[0]].shape)\n",
    "    VMean = np.zeros(Vs[epochs[0]].shape)\n",
    "    n, k = UMean.shape\n",
    "    m, k = VMean.shape\n",
    "    \n",
    "    # Create R (note that this function tries to read from disk if R already exists)\n",
    "    RTrain = createRatingSet(train, n, m, UserToU, JokeToV, 'R_Train1.out')\n",
    "    RTest = createRatingSet(test, n, m, UserToU, JokeToV, 'R_Test1.out')\n",
    "\n",
    "    \n",
    "    if useEpochs:\n",
    "        train_mse = []\n",
    "        train_avg = 0\n",
    "        test_mse = []\n",
    "        test_avg = 0\n",
    "        for epoch in epochs:\n",
    "            # We DO NOT AVERAGE Us, we average the likelihood's instead\n",
    "            UMean = Us[epoch] \n",
    "            VMean = Vs[epoch]\n",
    "\n",
    "            predictions = np.dot(UMean, VMean.T)\n",
    "\n",
    "            print \"Calculating log likelihood of training data for epoch {}\".format(epoch)\n",
    "\n",
    "            res = np.sum(vectSub(RTrain, predictions) ** 2) / float(len(train))\n",
    "            train_avg = (res + epoch * train_avg) / (epoch + 1)\n",
    "            train_mse.append(train_avg)\n",
    "            print \"Train Log Likelihood for Epoch {} is {}\".format(epoch, train_avg)\n",
    "\n",
    "            print \"Calculating log likelihood of testing data for epoch {}\".format(epoch)\n",
    "            res = np.sum(vectSub(RTest, predictions) ** 2) / float(len(test))\n",
    "            test_avg = (res + epoch * test_avg) / (epoch + 1)\n",
    "            test_mse.append(test_avg)\n",
    "            print \"Test Log Likelihood for Epoch {} is {}\".format(epoch, test_avg)\n",
    "\n",
    "        return test_mse, train_mse\n",
    "    else:\n",
    "        UTotal = Us[epochs[0]]\n",
    "        VTotal = Vs[epochs[0]]\n",
    "        for epoch in epochs[1:]:\n",
    "            UTotal += Us[epoch]\n",
    "            VTotal += Vs[epoch]\n",
    "        UMean = UTotal / float(len(epochs))\n",
    "        VMean = VTotal / float(len(epochs))\n",
    "        \n",
    "        predictions = np.dot(UMean, VMean.T)\n",
    "        \n",
    "        trainMSE = np.sum(vectSub(RTrain, predictions) ** 2) / float(len(train))\n",
    "        testMSE = np.sum(vectSub(RTest, predictions) ** 2) / float(len(test))\n",
    "        \n",
    "        return testMSE, trainMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parametrizeK(K):\n",
    "    testK = {}\n",
    "    trainK = {}\n",
    "    for k in range(1,K/2) + [K]:\n",
    "        # Run the Gibbs sampler on the data\n",
    "        Us, Vs, UserToU, UserToV, JokeToU, JokeToV = gibbsSampling(k, 100)\n",
    "        \n",
    "        # Calculate the log likelihood\n",
    "        test, train = getTrainTestLikelihood(Us, Vs, UserToU, JokeToV)\n",
    "        \n",
    "        testK[k] = test\n",
    "        trainK[k] = train\n",
    "        \n",
    "        print \"Finished for K = {}\".format(k)\n",
    "    return testK, trainK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testMSE, trainMSE = parametrizeK(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainMSE.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we just need to plot the results for the values of K\n",
    "from matplotlib.pyplot import cm \n",
    "\n",
    "K = 10\n",
    "color=iter(cm.rainbow(np.linspace(0,2,2*K)))\n",
    "for k in range(1,5) + [10]:\n",
    "    plt.scatter(range(101), testMSE[k], color=next(color), label=\"Test Data (K = {})\".format(k))\n",
    "    plt.scatter(range(101), trainMSE[k], color=next(color), label=\"Train Data (K = {})\".format(k))\n",
    "plt.title(\"MSE of Test and Training Data\")\n",
    "plt.xlabel(\"Dimension of Latent Variables\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.xlim((0,100))\n",
    "plt.ylim((0,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.concatenate(([1,2], [3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
